services:
  server:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "0.0.0.0:3001:3001"
    environment:
      - NODE_ENV=production
      - PORT=3001
      - TTS_SERVICE_URL=http://tts-service:5005
    volumes:
      - ebook-data:/app/data
      - ./client/build:/app/client/build:ro
    depends_on:
      tts-service:
        condition: service_healthy
    networks:
      - ebook-speaker
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3001/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    restart: unless-stopped
    stop_signal: SIGTERM
    stop_grace_period: 10s

  client-build:
    image: node:20-slim
    working_dir: /app
    volumes:
      - ./client:/app
      - /app/node_modules
    command: sh -c "npm install && npm run build"
    depends_on:
      - server

  tts-service:
    build:
      context: ./tts
      dockerfile: Dockerfile.cuda
    ports:
      - "0.0.0.0:5005:5005"
    environment:
      - PYTHONUNBUFFERED=1
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    runtime: nvidia
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
          memory: 1G
          cpus: '1.0'
        limits:
          memory: 4G
          cpus: '2.0'
    volumes:
      - tts-models:/app/models
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5005/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    restart: unless-stopped
    networks:
      - ebook-speaker
    stop_signal: SIGTERM
    stop_grace_period: 15s

networks:
  ebook-speaker:
    driver: bridge

volumes:
  ebook-data:
    driver: local
  tts-models:
    driver: local